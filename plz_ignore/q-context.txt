# Context File for learn_ai_enterprise_careers Repository

## Repository Overview
- **Location**: ~/darius_ai/p/learn_ai_enterprise_careers
- **GitHub**: git@github.com:darius-arian/learn_ai_enterprise_careers.git (SSH configured)
- **Owner Email**: sajad.rdel@gmail.com
- **Type**: Educational content for AI enterprise career development
- **License**: MIT

## Git Configuration
- SSH key configured at ~/.ssh/id_ed25519
- No password required for push/pull operations
- Remote uses SSH protocol

## Project Structure
```
learn_ai_enterprise_careers/
├── .git/
├── .gitignore
├── LICENSE
├── README.md
├── plz_ignore/
│   └── q-context.txt       # This file
└── videos/
    └── 01-aws-comprehend-review-analysis/
```

## Video 01: AWS Comprehend Review Analysis

### Architecture Overview
```
React Frontend → Express Backend → S3 → SQS → Lambda → AWS Comprehend → Results
```

**Full serverless pipeline for automated product review sentiment analysis**

### AWS Infrastructure (DEPLOYED & OPERATIONAL)
- **S3 Bucket**: `review-analysis-bucket-darius`
  - `01-aws-comprehend-review-analysis/review-analysis-uploads/` - uploaded JSON files
  - `01-aws-comprehend-review-analysis/analysis-results/` - Comprehend analysis results
- **SQS Queue**: `review-analysis-queue`
- **Lambda Function**: `review-analysis-processor` (Python 3.9)
- **IAM Role**: `review-analysis-lambda-role`
- **Region**: us-east-1

### Lambda Function (~/lambda_function.py)
**Comprehend Analysis Features (7 API calls per review):**
1. Language Detection (`detect_dominant_language`)
2. Sentiment Analysis (`detect_sentiment`)
3. Key Phrase Extraction (`detect_key_phrases`)
4. Entity Recognition (`detect_entities`)
5. Syntax Analysis (`detect_syntax`)
6. Targeted Sentiment (`detect_targeted_sentiment`)
7. PII Detection (`detect_pii_entities`)

**Key Implementation Details:**
- Extracts timestamp from uploaded filename for result file naming
- Handles multiple JSON structures (reviews array or nested product.reviews)
- Processes all reviews in batch
- Stores comprehensive analysis results back to S3

### Backend (Express.js)
**File**: `videos/01-aws-comprehend-review-analysis/backend/index.js`
**Port**: 3001

**Endpoints:**
- `POST /analyze` - Accepts JSON file upload, stores in S3, returns expectedResultFile
- `GET /results/:expectedResultFile` - Polls S3 for analysis results (200 if ready, 202 if processing)

**Features:**
- File validation (JSON only, max 1MB)
- Timestamp-based file naming (ISO format with hyphens)
- S3 integration with AWS SDK v3
- Environment-based configuration (.env file)

**Dependencies**: express, cors, multer, @aws-sdk/client-s3, dotenv

### Frontend (React + Vite)
**File**: `videos/01-aws-comprehend-review-analysis/frontend/src/App.jsx`
**Port**: 5173 (default Vite)

**Features:**
- File upload interface with validation
- Analysis trigger button
- Results polling with "See Results" button
- **Data Visualizations (Recharts):**
  - Language Distribution Pie Chart
  - Sentiment Distribution Bar Chart (color-coded: green=positive, red=negative, gray=neutral, orange=mixed)
- Responsive design (max-width: 1200px, centered)
- Full JSON results display

**Dependencies**: react, react-dom, recharts, vite

### Development Setup
**Backend:**
```bash
cd videos/01-aws-comprehend-review-analysis/backend
npm install
npm start  # Runs on port 3001
```

**Frontend:**
```bash
cd videos/01-aws-comprehend-review-analysis/frontend
npm install
npm run dev  # Runs on port 5173
```

**Run both in background:**
```bash
cd frontend && nohup npm run dev > frontend.log 2>&1 &
cd backend && nohup npm start > backend.log 2>&1 &
```

**Stop servers:**
```bash
pkill -f "node index.js"
pkill -f "vite"
```

### Data Flow
1. User uploads JSON file via frontend
2. Backend validates and uploads to S3 with timestamp
3. S3 event triggers SQS message
4. Lambda processes SQS message, reads file from S3
5. Lambda calls Comprehend APIs for each review
6. Lambda saves results to S3 with matching timestamp
7. Frontend polls backend for results
8. Backend checks S3 for result file
9. Results displayed with charts and full JSON

### Sample Data
**Location**: `videos/01-aws-comprehend-review-analysis/data/product-reviews.json`
Contains product reviews for testing the analysis pipeline

### Recent Updates
- Fixed timestamp format mismatch between backend and Lambda
- Added Recharts visualizations (language pie chart, sentiment bar chart)
- Made frontend responsive
- Improved results polling with direct S3 key lookup
- Added dark text color for better readability

### Technology Stack
- **Frontend**: React 19, Vite 7, Recharts, ESLint
- **Backend**: Express 4, AWS SDK v3, Multer, dotenv
- **AWS**: S3, SQS, Lambda, Comprehend, IAM
- **Runtime**: Node.js (frontend/backend), Python 3.9 (Lambda)

### Logs
- Frontend: `videos/01-aws-comprehend-review-analysis/frontend/frontend.log`
- Backend: `videos/01-aws-comprehend-review-analysis/backend/backend.log`

## Notes for AI Assistant
- Project is fully operational with complete AWS pipeline
- SSH authentication configured - no password prompts
- Lambda function updated to match backend timestamp format
- All 7 Comprehend features are active and working
- Frontend includes interactive data visualizations
- Use ~/lambda_function.py for Lambda updates, then zip and deploy via AWS CLI
